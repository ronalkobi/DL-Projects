{"cells":[{"cell_type":"markdown","metadata":{"id":"cfMwbvOQKRi-"},"source":["# RAG with LangChain"]},{"cell_type":"markdown","metadata":{"id":"SnTBIh6PKRi-"},"source":["Objective: Building a knowledge base chatbot capable of learning from the external world using **R**etrieval **A**ugmented **G**eneration (RAG).\n","\n","Stack: LangChain, OpenAI, and Pinecone vector DB\n","\n","Data: Llama 2 ArXiv paper and other related papers.\n"]},{"cell_type":"markdown","metadata":{"id":"ZcR1Ef_PKRi_"},"source":["## Install liberties"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4JU3o0FQKRi_"},"outputs":[],"source":["!pip install -qU \\\n","    langchain==0.0.292 \\\n","    openai==0.28.0 \\\n","    datasets==2.10.1 \\\n","    pinecone-client==2.2.4 \\\n","    tiktoken==0.5.1"]},{"cell_type":"markdown","source":["\n","## First, lets build a simple chat without RAG capabilities."],"metadata":{"id":"r0ZaMyNrPnJp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pUV0HHHiKRjB"},"outputs":[],"source":["import os\n","from langchain.chat_models import ChatOpenAI\n","\n","os.environ[\"OPENAI_API_KEY\"] = \"******\"\n","\n","chat = ChatOpenAI(\n","    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n","    model='gpt-3.5-turbo'\n",")"]},{"cell_type":"markdown","metadata":{"id":"6jy1pQtSKRjB"},"source":["\n","#### LangChain chat format _message_ objects:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"laDF6bKgKRjB"},"outputs":[],"source":["from langchain.schema import (\n","    SystemMessage,\n","    HumanMessage,\n","    AIMessage\n",")\n","\n","messages = [\n","    SystemMessage(content=\"You are a helpful assistant.\"),\n","    HumanMessage(content=\"Hi AI, how are you today?\"),\n","    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n","    HumanMessage(content=\"I'd like to understand string theory.\")\n","]"]},{"cell_type":"markdown","metadata":{"id":"X7CjyFlLKRjB"},"source":["#### We generate the next response from the AI by passing these messages to the `ChatOpenAI` object."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZnCvN8s3KRjC","executionInfo":{"status":"ok","timestamp":1702236332508,"user_tz":-120,"elapsed":18148,"user":{"displayName":"Ron Alkobi","userId":"06824546943851514341"}},"outputId":"abe0f1ee-e1a2-44c7-a7bc-f1dc76a41ad1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content=\"String theory is a theoretical framework in physics that aims to explain the fundamental nature of particles and the forces between them. It suggests that at the smallest scales of existence, particles are not point-like but instead tiny, vibrating strings.\\n\\nHere are some key points to help you understand string theory:\\n\\n1. Basic Idea: According to string theory, the fundamental building blocks of the universe are not particles but tiny strings, similar to the strings of a musical instrument. These strings can vibrate at different frequencies, and the different vibrational patterns give rise to different particles and their properties.\\n\\n2. Extra Dimensions: String theory requires extra dimensions beyond the three spatial dimensions (length, width, and height) that we experience in everyday life. These extra dimensions are compactified or curled up so small that we don't directly perceive them.\\n\\n3. Unifying Theory: One of the main motivations behind string theory is its potential to unify all the fundamental forces of nature. In the standard model of particle physics, there are four fundamental forces: gravity, electromagnetism, and the strong and weak nuclear forces. String theory attempts to provide a framework that encompasses all these forces within a single, consistent theory.\\n\\n4. Mathematical Framework: String theory relies heavily on advanced mathematical concepts, such as geometry, topology, and quantum mechanics. It combines ideas from quantum mechanics and general relativity to describe the behavior of strings and their interactions.\\n\\n5. Multiple Versions: There are several different versions of string theory, such as Type I, Type IIA, Type IIB, heterotic SO(32), and heterotic E8×E8. Each version has its own unique properties and mathematical framework, but they are believed to be related through a concept called dualities.\\n\\n6. Challenges: Despite its promise, string theory still faces many challenges. It is a highly complex and mathematically demanding theory, making it difficult to test experimentally. Additionally, there is no definitive experimental evidence to support string theory at present, which makes it more of a theoretical framework than an established scientific theory.\\n\\nIt's worth noting that string theory is an active area of research, and scientists continue to explore its implications and potential connections to other theories.\", additional_kwargs={}, example=False)"]},"metadata":{},"execution_count":5}],"source":["res = chat(messages)\n","res"]},{"cell_type":"markdown","metadata":{"id":"TgqR8sFYKRjI"},"source":["####In response we get another AI message object. We can print it more clearly like so:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zzdk_axaKRjI","executionInfo":{"status":"ok","timestamp":1702236341877,"user_tz":-120,"elapsed":387,"user":{"displayName":"Ron Alkobi","userId":"06824546943851514341"}},"outputId":"e051e2cc-456a-42f7-bf3f-8fecad911a58"},"outputs":[{"output_type":"stream","name":"stdout","text":["String theory is a theoretical framework in physics that aims to explain the fundamental nature of particles and the forces between them. It suggests that at the smallest scales of existence, particles are not point-like but instead tiny, vibrating strings.\n","\n","Here are some key points to help you understand string theory:\n","\n","1. Basic Idea: According to string theory, the fundamental building blocks of the universe are not particles but tiny strings, similar to the strings of a musical instrument. These strings can vibrate at different frequencies, and the different vibrational patterns give rise to different particles and their properties.\n","\n","2. Extra Dimensions: String theory requires extra dimensions beyond the three spatial dimensions (length, width, and height) that we experience in everyday life. These extra dimensions are compactified or curled up so small that we don't directly perceive them.\n","\n","3. Unifying Theory: One of the main motivations behind string theory is its potential to unify all the fundamental forces of nature. In the standard model of particle physics, there are four fundamental forces: gravity, electromagnetism, and the strong and weak nuclear forces. String theory attempts to provide a framework that encompasses all these forces within a single, consistent theory.\n","\n","4. Mathematical Framework: String theory relies heavily on advanced mathematical concepts, such as geometry, topology, and quantum mechanics. It combines ideas from quantum mechanics and general relativity to describe the behavior of strings and their interactions.\n","\n","5. Multiple Versions: There are several different versions of string theory, such as Type I, Type IIA, Type IIB, heterotic SO(32), and heterotic E8×E8. Each version has its own unique properties and mathematical framework, but they are believed to be related through a concept called dualities.\n","\n","6. Challenges: Despite its promise, string theory still faces many challenges. It is a highly complex and mathematically demanding theory, making it difficult to test experimentally. Additionally, there is no definitive experimental evidence to support string theory at present, which makes it more of a theoretical framework than an established scientific theory.\n","\n","It's worth noting that string theory is an active area of research, and scientists continue to explore its implications and potential connections to other theories.\n"]}],"source":["print(res.content)"]},{"cell_type":"markdown","metadata":{"id":"zD_uiziIKRjJ"},"source":["####Because `res` is just another `AIMessage` object, we can append it to `messages`, add another `HumanMessage`, and generate the next response in the conversation."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O1zxgFS0KRjJ","executionInfo":{"status":"ok","timestamp":1702236375491,"user_tz":-120,"elapsed":17209,"user":{"displayName":"Ron Alkobi","userId":"06824546943851514341"}},"outputId":"11969bf9-0139-495e-b051-2f08f806af9f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Physicists believe that string theory has the potential to produce a unified theory because it incorporates both quantum mechanics and general relativity, two foundational theories in physics that have been highly successful in their respective domains but are incompatible with each other.\n","\n","1. Resolving Incompatibility: Quantum mechanics describes the behavior of particles on extremely small scales, such as atoms and subatomic particles, while general relativity describes the behavior of gravity on large scales, such as the motion of planets and the structure of the universe. However, when physicists try to combine these two theories, they encounter mathematical inconsistencies and infinities. String theory attempts to overcome these issues by providing a framework that reconciles quantum mechanics and general relativity.\n","\n","2. Theory of Everything: A unified theory, often referred to as a \"theory of everything,\" would describe all fundamental forces and particles in a consistent and coherent manner. String theory has the potential to achieve this because it naturally incorporates gravity, electromagnetism, and the strong and weak nuclear forces as different vibrational patterns of the strings. It suggests that all particles and their interactions arise from the vibrations of these strings.\n","\n","3. Duality Symmetries: String theory exhibits a concept called \"dualities,\" which suggests that seemingly different versions of the theory are actually equivalent descriptions of the same underlying physics. This means that different versions of string theory, with different numbers of dimensions or particle content, are related to each other. Duality symmetries provide a powerful tool to explore the connections between different physical phenomena and can help in formulating a unified theory.\n","\n","4. Consistency and Beauty: Physicists are drawn to string theory because of its mathematical elegance and internal consistency. The theory has a rich mathematical structure that brings together ideas from geometry, topology, and quantum mechanics. Many physicists believe that the beauty and mathematical coherence of string theory indicate that it may hold the key to a unified description of the universe.\n","\n","However, it's important to note that while string theory shows promise, it has not yet been experimentally confirmed. Ongoing research is focused on finding ways to test and validate the predictions of string theory, which would provide stronger evidence for its validity as a unified theory.\n"]}],"source":["# add latest AI response to messages\n","messages.append(res)\n","\n","# now create a new user prompt\n","prompt = HumanMessage(\n","    content=\"Why do physicists believe it can produce a 'unified theory'?\"\n",")\n","# add to messages\n","messages.append(prompt)\n","\n","# send to chat-gpt\n","res = chat(messages)\n","\n","print(res.content)"]},{"cell_type":"markdown","metadata":{"id":"jFpDKB-VKRjJ"},"source":["### Dealing with Hallucinations"]},{"cell_type":"markdown","metadata":{"id":"odPJmqQMKRjJ"},"source":["By default, LLMs have no access to the external world.\n","\n","LLM precive the world as seen in the training data, this kind of knowledge called the _parametric knowledge_.\n","\n","So if we'll ask our LLMs about up-to-date topics which it never trained on (like Llama 2 in our case), it'll be strugeeling to provide us with an appropriate response.\n","\n","Let's give it a shot and see what's happening."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gbRKUebiKRjK"},"outputs":[],"source":["# add latest AI response to messages\n","messages.append(res)\n","\n","# now create a new user prompt\n","prompt = HumanMessage(\n","    content=\"What is so special about Llama 2?\"\n",")\n","# add to messages\n","messages.append(prompt)\n","\n","# send to OpenAI\n","res = chat(messages)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zEe8NCMzKRjK","executionInfo":{"status":"ok","timestamp":1702236387570,"user_tz":-120,"elapsed":473,"user":{"displayName":"Ron Alkobi","userId":"06824546943851514341"}},"outputId":"6394676e-d3a1-4233-d134-87983ab41f4f"},"outputs":[{"output_type":"stream","name":"stdout","text":["I'm sorry, I am not aware of any specific reference or context to \"Llama 2\" that would allow me to provide an answer. Could you please provide more information or clarify your question?\n"]}],"source":["print(res.content)"]},{"cell_type":"markdown","metadata":{"id":"RLBeD9xwKRjK"},"source":["As mentioned above, since our chatbot doesn contain the information we need to answer the question, it can no longer help us."]},{"cell_type":"markdown","source":["#### Let's see one way of feeding knowledge into LLMs. It is called _source knowledge_ and it refers to any information fed into the LLM via the prompt."],"metadata":{"id":"fp_Yi7PEUvo7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hvUiDAHSKRjK"},"outputs":[],"source":["# add latest AI response to messages\n","messages.append(res)\n","\n","# now create a new user prompt\n","prompt = HumanMessage(\n","    content=\"Can you tell me about the LLMChain in LangChain?\"\n",")\n","# add to messages\n","messages.append(prompt)\n","\n","# send to OpenAI\n","res = chat(messages)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HYo9WYd1KRjL","executionInfo":{"status":"ok","timestamp":1702236404978,"user_tz":-120,"elapsed":413,"user":{"displayName":"Ron Alkobi","userId":"06824546943851514341"}},"outputId":"4ba132c0-e733-47fa-a879-4ce1acc4c894"},"outputs":[{"output_type":"stream","name":"stdout","text":["I apologize, but I am not familiar with specific details about a technology called \"LLMChain\" in \"LangChain.\" It is possible that these terms are specific to a particular project or system that is not widely known or recognized. Without further information, it is difficult for me to provide any specific details or insights. If you can provide more context or background information, I will do my best to assist you.\n"]}],"source":["print(res.content)"]},{"cell_type":"markdown","metadata":{"id":"kJIoFV0dKRjL"},"source":["Let's take a description of this object from the LangChain documentation and try using that with the LLMChain question."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jadZaUISKRjL"},"outputs":[],"source":["llmchain_information = [\n","    \"A LLMChain is the most common type of chain. It consists of a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser. This chain takes multiple input variables, uses the PromptTemplate to format them into a prompt. It then passes that to the model. Finally, it uses the OutputParser (if provided) to parse the output of the LLM into a final format.\",\n","    \"Chains is an incredibly generic concept which returns to a sequence of modular components (or other chains) combined in a particular way to accomplish a common use case.\",\n","    \"LangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also: (1) Be data-aware: connect a language model to other sources of data, (2) Be agentic: Allow a language model to interact with its environment. As such, the LangChain framework is designed with the objective in mind to enable those types of applications.\"\n","]\n","\n","source_knowledge = \"\\n\".join(llmchain_information)"]},{"cell_type":"markdown","metadata":{"id":"dXMBCLSFKRjL"},"source":["We can feed this additional knowledge into our prompt with some instructions telling the LLM how we'd like it to use this information alongside our original query."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yl3yru0PKRjM"},"outputs":[],"source":["query = \"Can you tell me about the LLMChain in LangChain?\"\n","\n","augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n","\n","Contexts:\n","{source_knowledge}\n","\n","Query: {query}\"\"\""]},{"cell_type":"markdown","metadata":{"id":"Jz4txx8bKRjM"},"source":["Now we feed this into our chatbot as we were before."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_2dsfwhZKRjM"},"outputs":[],"source":["# create a new user prompt\n","prompt = HumanMessage(\n","    content=augmented_prompt\n",")\n","# add to messages\n","messages.append(prompt)\n","\n","# send to OpenAI\n","res = chat(messages)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PzOzzO79KRjN","executionInfo":{"status":"ok","timestamp":1702208180342,"user_tz":-120,"elapsed":3,"user":{"displayName":"Ron Alkobi","userId":"06824546943851514341"}},"outputId":"92f37f1b-fb5e-4452-b821-680c2ae7e1ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["LLMChain is a type of chain within the LangChain framework. Chains, in general, refer to a sequence of modular components combined in a specific way to achieve a common purpose. In the context of LangChain, a chain consists of a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser.\n","\n","Specifically, an LLMChain is the most common type of chain in LangChain. It takes multiple input variables, uses the PromptTemplate to format them into a prompt, and passes it to the language model (LLM). The language model generates a response based on the prompt. Additionally, the LLMChain may include an optional output parser, which is used to parse the output of the language model into a final format.\n","\n","The purpose of LangChain as a framework is to develop applications powered by language models. It aims to go beyond simply calling out to a language model via an API. LangChain emphasizes two key aspects: being data-aware and being agentic.\n","\n","Being data-aware means that LangChain enables the connection of a language model to other sources of data, allowing it to incorporate and utilize additional information beyond the language model itself.\n","\n","Being agentic refers to the ability of a language model within the LangChain framework to interact with its environment. This interaction allows for more dynamic and contextual applications by enabling the language model to actively engage with the user or the surrounding system.\n","\n","Overall, the LLMChain is a fundamental component in the LangChain framework, facilitating the interaction between prompts, language models, and output parsing to create powerful and differentiated applications that leverage language models in a data-aware and agentic manner.\n"]}],"source":["print(res.content)"]},{"cell_type":"markdown","metadata":{"id":"lgI0s1ROKRjN"},"source":["Thanks to the idea of augmented query with external knowledge, it's possible to answer questions outside of the model original knowledge boundaries.\n","And as we can see, the answer quality is fantastic.\n","\n","Now we left we with question - how do we get this information in the first place?\n","The answer : Pinecone and vector databases.\n","\n","First, let's get a dataset."]},{"cell_type":"markdown","metadata":{"id":"agaJLHrvKRjN"},"source":["### Importing the Data"]},{"cell_type":"markdown","metadata":{"id":"2RQsZcIaKRjN"},"source":["We will be using the Hugging Face Datasets library to load our data.  \n","The dataset is : `\"jamescalam/llama-2-arxiv-papers\"`.\n","Which contains Llama 2 ArXiv papers, a collection of academic papers from ArXiv,\n","a repository of electronic preprints approved for publication after moderation\n","This will serve as the external knowledge base for our chatbot."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":290,"referenced_widgets":["be77a53c5b504d0c9e61051945075d75","26a3c8ef0c924b5a994cc9c1c571a0bb","e72b2017a11d4ccebf85aeb5d766797b","d1fd6fc5669f4e06a0dea5a375978e3f","d68bac75b3f64dd0ada66816957f685c","43572a2561ce46a09fbc6e2b3b6f1ee7","11707d43cd0c4eb688764d47bd996a89","be20f87598d44bd69c4feb88aa06fba6","f51a71e4773d4a00b7d988ec57843f10","452c59656294495eac2c4068ff46d9e0","9c10a94a32904eaa9d8994579403d225","e4c3b06b569f4d3ca03d1dc34ade186c","8bfd7cf50fb74a5e83de8481e7d5f096","8b5b0caa99e343269349d099caa32400","f2edb54556e6467bae3e593bf21d3587","2d2e5eff50da4ad5969a96b65e4b8255","f35565d6b57a4caabd190a359381dec8","5f03b7265e9949c5bafe28c0f3c82a8a","46d3f10caf044d31b37414caf155bcdf","5eebbe28d48941398e16f58f5030cf25","a04928ba7fac4a5fa723b84048354849","4c521cfa98d441d790e5b3df709e79d3","933016f0f472436da4dad83a422b3191","71dfa555bbbe4516a39f32e563adc544","803e49c5d93845c3b0851e428e00718e","53ac9402ac604404a875fbd409f4b254","7e63974c92ee48daa5fc3fcd426747f6","baa24b7df0ce459bb55164d5dea6e824","d47e9e01ffca4b9a8c0a9ad8cf1df0cb","0df48c933c844e648b5c95b6be69b8a7","dba0cdd2ceae4816a03a028b51597763","d0cebd9be5194a0f8c3ff4f24fc5a28d","a2b83a3410204bc18783f3d11683ece5","86312d730fa042d9967c31e40d55ae14","0b86daa5441a48e89140e83e99b930d7","432c8285487541c494ec4ba8bfa45866","61f66f846a434070bafb551653a90a48","0daf46499af94c59ac39ef15d59157dc","8a76ac8ea4754380b7a1163d83a4f677","5eda70b126eb49a88130fe8a60f0677a","95c6e9ec51534eeaa23824e511e09cd2","cc1628b74c3c4d57a058158f13aeed5c","50d8a608cb5f43069eeac130c72c85dd","93f29f9c5daf4e30a378dd8d8006d817","20fdabe2017446cab7d80adf31dc5edc","fa15182dee014e0493770159c6fba390","fd16cbe37d8847eda9417ec4eaa6d3eb","afde652bddaa4a3e81eb3fb64e47b97e","cc6bb80be5e842ef89ff6cdc8c1243b2","0101f9747c714c06a737370bc1616edf","a1c8a081bd454206b3005c34f6a26f38","6ca96c4da99945f1b96c7caf12d64d75","a004fde8d6d74bf4b3b2128d9dd40f75","a3a2b9f4795745e6bec8eb110c002e03","cedbc6b305cb402295f312bddcdb0c5a"]},"id":"qz_Y5Nc6KRjN","executionInfo":{"status":"ok","timestamp":1702210085199,"user_tz":-120,"elapsed":3709,"user":{"displayName":"Ron Alkobi","userId":"06824546943851514341"}},"outputId":"43416ca6-3df8-42ea-b063-ccffb2a2b423"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading readme:   0%|          | 0.00/409 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be77a53c5b504d0c9e61051945075d75"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset json/jamescalam--llama-2-arxiv-papers-chunked to /root/.cache/huggingface/datasets/jamescalam___json/jamescalam--llama-2-arxiv-papers-chunked-ea255a807f3039a6/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4c3b06b569f4d3ca03d1dc34ade186c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/14.4M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"933016f0f472436da4dad83a422b3191"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86312d730fa042d9967c31e40d55ae14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20fdabe2017446cab7d80adf31dc5edc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/jamescalam___json/jamescalam--llama-2-arxiv-papers-chunked-ea255a807f3039a6/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51. Subsequent calls will reuse this data.\n"]},{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['doi', 'chunk-id', 'chunk', 'id', 'title', 'summary', 'source', 'authors', 'categories', 'comment', 'journal_ref', 'primary_category', 'published', 'updated', 'references'],\n","    num_rows: 4838\n","})"]},"metadata":{},"execution_count":21}],"source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\n","    \"jamescalam/llama-2-arxiv-papers-chunked\",\n","    split=\"train\"\n",")\n","\n","dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C1OKEfXJKRjN","executionInfo":{"status":"ok","timestamp":1702210089884,"user_tz":-120,"elapsed":303,"user":{"displayName":"Ron Alkobi","userId":"06824546943851514341"}},"outputId":"da69a52e-3b28-4a6d-b9a6-5105d1fb04e0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'doi': '1102.0183',\n"," 'chunk-id': '0',\n"," 'chunk': 'High-Performance Neural Networks\\nfor Visual Object Classi\\x0ccation\\nDan C. Cire\\x18 san, Ueli Meier, Jonathan Masci,\\nLuca M. Gambardella and J\\x7f urgen Schmidhuber\\nTechnical Report No. IDSIA-01-11\\nJanuary 2011\\nIDSIA / USI-SUPSI\\nDalle Molle Institute for Arti\\x0ccial Intelligence\\nGalleria 2, 6928 Manno, Switzerland\\nIDSIA is a joint institute of both University of Lugano (USI) and University of Applied Sciences of Southern Switzerland (SUPSI),\\nand was founded in 1988 by the Dalle Molle Foundation which promoted quality of life.\\nThis work was partially supported by the Swiss Commission for Technology and Innovation (CTI), Project n. 9688.1 IFF:\\nIntelligent Fill in Form.arXiv:1102.0183v1  [cs.AI]  1 Feb 2011\\nTechnical Report No. IDSIA-01-11 1\\nHigh-Performance Neural Networks\\nfor Visual Object Classi\\x0ccation\\nDan C. Cire\\x18 san, Ueli Meier, Jonathan Masci,\\nLuca M. Gambardella and J\\x7f urgen Schmidhuber\\nJanuary 2011\\nAbstract\\nWe present a fast, fully parameterizable GPU implementation of Convolutional Neural\\nNetwork variants. Our feature extractors are neither carefully designed nor pre-wired, but',\n"," 'id': '1102.0183',\n"," 'title': 'High-Performance Neural Networks for Visual Object Classification',\n"," 'summary': 'We present a fast, fully parameterizable GPU implementation of Convolutional\\nNeural Network variants. Our feature extractors are neither carefully designed\\nnor pre-wired, but rather learned in a supervised way. Our deep hierarchical\\narchitectures achieve the best published results on benchmarks for object\\nclassification (NORB, CIFAR10) and handwritten digit recognition (MNIST), with\\nerror rates of 2.53%, 19.51%, 0.35%, respectively. Deep nets trained by simple\\nback-propagation perform better than more shallow ones. Learning is\\nsurprisingly rapid. NORB is completely trained within five epochs. Test error\\nrates on MNIST drop to 2.42%, 0.97% and 0.48% after 1, 3 and 17 epochs,\\nrespectively.',\n"," 'source': 'http://arxiv.org/pdf/1102.0183',\n"," 'authors': ['Dan C. Cireşan',\n","  'Ueli Meier',\n","  'Jonathan Masci',\n","  'Luca M. Gambardella',\n","  'Jürgen Schmidhuber'],\n"," 'categories': ['cs.AI', 'cs.NE'],\n"," 'comment': '12 pages, 2 figures, 5 tables',\n"," 'journal_ref': None,\n"," 'primary_category': 'cs.AI',\n"," 'published': '20110201',\n"," 'updated': '20110201',\n"," 'references': []}"]},"metadata":{},"execution_count":22}],"source":["dataset[0]"]},{"cell_type":"markdown","metadata":{"id":"G4_zb2qnKRjO"},"source":["### Building the Knowledge Base"]},{"cell_type":"markdown","metadata":{"id":"KM69QOpJKRjO"},"source":["Now after we get data that will serve our knowledge base, we need transform the database into the knowledge base that our chatbot can use.\n","For that, we need to use an embedding model and vector database.\n","\n","\n","We begin by initializing our connection to Pinecone."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z0yJapFxKRjf"},"outputs":[],"source":["import pinecone\n","\n","# get API key from app.pinecone.io and environment from console\n","pinecone.init(\n","    api_key=os.environ.get('PINECONE_API_KEY') or '921c6073-f26c-4354-b567-092b515d6699',\n","    environment=os.environ.get('PINECONE_ENVIRONMENT') or 'gcp-starter'\n",")"]},{"cell_type":"markdown","metadata":{"id":"RvxiCeUuKRjf"},"source":["Then we initialize the index. We will be using OpenAI's `text-embedding-ada-002` model for creating the embeddings, so we set the `dimension` to `1536`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qtI72BHgKRjf"},"outputs":[],"source":["import time\n","\n","index_name = 'llama-2-rag'\n","\n","if index_name not in pinecone.list_indexes():\n","    pinecone.create_index(\n","        index_name,\n","        dimension=1536,\n","        metric='cosine'\n","    )\n","    # wait for index to finish initialization\n","    while not pinecone.describe_index(index_name).status['ready']:\n","        time.sleep(1)\n","\n","index = pinecone.Index(index_name)"]},{"cell_type":"markdown","metadata":{"id":"jaTY6kYBKRjg"},"source":["Then we connect to the index:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PVs-nmyBKRjg","executionInfo":{"status":"ok","timestamp":1702210192985,"user_tz":-120,"elapsed":961,"user":{"displayName":"Ron Alkobi","userId":"06824546943851514341"}},"outputId":"cbb6f2f9-4089-4cd2-df27-08aebb22905d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'dimension': 1536,\n"," 'index_fullness': 0.0,\n"," 'namespaces': {},\n"," 'total_vector_count': 0}"]},"metadata":{},"execution_count":29}],"source":["index.describe_index_stats()"]},{"cell_type":"markdown","metadata":{"id":"Z1BftsF1KRjg"},"source":["Our index is now ready but it's empty. It is a vector index, so it needs vectors.\n","To create these vector embeddings we will OpenAI's `text-embedding-ada-002` model which can be accessed via LangChain:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JVfSSEl4KRjg"},"outputs":[],"source":["from langchain.embeddings.openai import OpenAIEmbeddings\n","\n","embed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"]},{"cell_type":"markdown","metadata":{"id":"WsbOnUJgKRjh"},"source":["Let's embed and index all our our data.\n","We do this by looping through our dataset- embedding and inserting all in batches."]},{"cell_type":"code","source":["from tqdm.auto import tqdm  # for progress bar\n","\n","data = dataset.to_pandas()  # this makes it easier to iterate over the dataset\n","\n","batch_size = 100\n","\n","for i in tqdm(range(0, len(data), batch_size)):\n","    i_end = min(len(data), i+batch_size)\n","    # get batch of data\n","    batch = data.iloc[i:i_end]\n","    # generate unique ids for each chunk\n","    ids = [f\"{x['doi']}-{x['chunk-id']}\" for i, x in batch.iterrows()]\n","    # get text to embed\n","    texts = [x['chunk'] for _, x in batch.iterrows()]\n","    # embed text\n","    embeds = embed_model.embed_documents(texts)\n","    # get metadata to store in Pinecone\n","    metadata = [\n","        {'text': x['chunk'],\n","         'source': x['source'],\n","         'title': x['title']} for i, x in batch.iterrows()\n","    ]\n","    # add to Pinecone\n","    index.upsert(vectors=zip(ids, embeds, metadata))"],"metadata":{"id":"l8-t_afxqrlA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YXBWu0yAKRjh"},"source":["check the vector is populates:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"06EsWs4qKRji","outputId":"3a7765c7-6486-4b80-eb20-13ad270d0ca3"},"outputs":[{"data":{"text/plain":["{'dimension': 1536,\n"," 'index_fullness': 0.0,\n"," 'namespaces': {'': {'vector_count': 4838}},\n"," 'total_vector_count': 4838}"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["index.describe_index_stats()"]},{"cell_type":"markdown","metadata":{"id":"7SotKyF5KRji"},"source":["#### Retrieval Augmented Generation"]},{"cell_type":"markdown","metadata":{"id":"DGyh8Q_KKRji"},"source":["Now it's time to connect that knowledge base to our chatbot.\n","For that, we'll reusing our LangChain template prompt from earlier."]},{"cell_type":"markdown","metadata":{"id":"rJaescDrKRji"},"source":[" We pass in our vector `index` to initialize the object."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xpLqeq8FKRji"},"outputs":[],"source":["from langchain.vectorstores import Pinecone\n","\n","text_field = \"text\"  # the metadata field that contains our text\n","\n","# initialize the vector store object\n","vectorstore = Pinecone(\n","    index, embed_model.embed_query, text_field\n",")"]},{"cell_type":"markdown","metadata":{"id":"CzsPzmblKRji"},"source":["Query the index using `vectorstore` and see what we got."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tIVBtq8aKRjj","outputId":"763bd9f5-50c9-4833-e9df-bea57e82fc20"},"outputs":[{"data":{"text/plain":["[Document(page_content='Alan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom\\x03\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and ﬁne-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur ﬁne-tuned LLMs, called L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosedsource models. We provide a detailed description of our approach to ﬁne-tuning and safety', metadata={'source': 'http://arxiv.org/pdf/2307.09288', 'title': 'Llama 2: Open Foundation and Fine-Tuned Chat Models'}),\n"," Document(page_content='asChatGPT,BARD,andClaude. TheseclosedproductLLMsareheavilyﬁne-tunedtoalignwithhuman\\npreferences, which greatly enhances their usability and safety. This step can require signiﬁcant costs in\\ncomputeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\\nthe community to advance AI alignment research.\\nIn this work, we develop and release Llama 2, a family of pretrained and ﬁne-tuned LLMs, L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle and\\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc , at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,\\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc models generally perform better than existing open-source models. They also appear to\\nbe on par with some of the closed-source models, at least on the human evaluations we performed (see', metadata={'source': 'http://arxiv.org/pdf/2307.09288', 'title': 'Llama 2: Open Foundation and Fine-Tuned Chat Models'}),\n"," Document(page_content='Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aur’elien Rodriguez, Armand Joulin, Edouard\\nGrave, and Guillaume Lample. Llama: Open and eﬃcient foundation language models. arXiv preprint\\narXiv:2302.13971 , 2023.\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser,\\nand Illia Polosukhin. Attention is all you need, 2017.\\nOriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki, Michaël Mathieu, Andrew Dudzik, Junyoung Chung,\\nDavid H Choi, Richard Powell, Timo Ewalds, Petko Georgiev, et al. Grandmaster level in starcraft ii using\\nmulti-agent reinforcement learning. Nature, 575(7782):350–354, 2019.\\nYizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and HannanehHajishirzi. Self-instruct: Aligninglanguagemodel withselfgeneratedinstructions. arXivpreprint', metadata={'source': 'http://arxiv.org/pdf/2307.09288', 'title': 'Llama 2: Open Foundation and Fine-Tuned Chat Models'})]"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["query = \"What is so special about Llama 2?\"\n","\n","vectorstore.similarity_search(query, k=3)"]},{"cell_type":"markdown","metadata":{"id":"9kX95DogKRjj"},"source":["A lot of text returned and it's not clear what is relevant and what is not.\n","\n","Fortunately, our LLM is capable to shape things up.\n","\n","All we need is to connect the `vectorstore` output to the `chat` chatbot. For that, we'll use the same logic from earlier."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eD8cX3duKRjj"},"outputs":[],"source":["def augment_prompt(query: str):\n","    # get top 3 results from knowledge base\n","    results = vectorstore.similarity_search(query, k=3)\n","    # get the text from the results\n","    source_knowledge = \"\\n\".join([x.page_content for x in results])\n","    # feed into an augmented prompt\n","    augmented_prompt = f\"\"\" Using the contexts below, answer the query.\n","\n","    Contexts:\n","    {source_knowledge}\n","\n","    Query: {query} \"\"\"\n","    return augmented_prompt"]},{"cell_type":"markdown","metadata":{"id":"SphdKGJiKRjk"},"source":["Let's pass it onto our chat model to see how it performs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y-32PNPXKRjk","outputId":"7faf2cdc-dffd-4adb-d3f1-4d56bb1ffb57"},"outputs":[{"name":"stdout","output_type":"stream","text":["Llama 2 is a collection of pretrained and fine-tuned large language models (LLMs) that range in scale from 7 billion to 70 billion parameters. These LLMs, such as L/l.sc/a.sc/m.sc/a.sc/t.sc and L/l.sc/a.sc/m.sc/a.sc/t.sc-C/h.sc/a.sc/t.sc, are specifically optimized for dialogue use cases.\n","\n","The special aspect of Llama 2 is that its fine-tuned LLMs outperform open-source chat models on various benchmarks, demonstrating superior performance. In fact, based on humane evaluations for helpfulness and safety, Llama 2 models are considered as potential substitutes for closed-source models. Closed-source models like ChatGPT, BARD, and Claude are heavily fine-tuned to align with human preferences, enhancing usability and safety.\n","\n","The development and release of Llama 2 contribute to the progress of AI alignment research, as it provides transparent and reproducible approaches to fine-tuning and safety. This is in contrast to closed-source models, which often lack transparency and hinder community advancements in the field.\n","\n","Overall, the special features of Llama 2 lie in its large-scale pretrained and fine-tuned LLMs that excel in dialogue applications and its commitment to transparency and reproducibility in research.\n"]}],"source":["# create a new user prompt\n","prompt = HumanMessage(\n","    content=augment_prompt(query)\n",")\n","# add to messages\n","messages.append(prompt)\n","\n","res = chat(messages)\n","\n","print(res.content)"]},{"cell_type":"markdown","metadata":{"id":"F-56sSsJKRjk"},"source":["Now Let's try _without_ RAG:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6AcRfGp6KRjk","outputId":"e9f792c3-0765-4d0d-fd2e-66c296abf40b"},"outputs":[{"name":"stdout","output_type":"stream","text":["According to the provided context, the paper mentions that they provide a detailed description of their approach to fine-tuning and safety, similar to other closed-source models like ChatGPT, BARD, and Claude. However, the specific safety measures used in the development of Llama 2 are not mentioned in the given context. To obtain more detailed information about the safety measures employed in Llama 2, it would be necessary to refer to the original paper or additional sources related to Llama 2.\n"]}],"source":["prompt = HumanMessage(\n","    content=\"what safety measures were used in the development of llama 2?\"\n",")\n","\n","res = chat(messages + [prompt])\n","print(res.content)"]},{"cell_type":"markdown","metadata":{"id":"PZY8RZ_fKRjk"},"source":[" Thanks to it's conversational history stored in `messages`, The chatbot is able to respond about Llama2.\n","\n"," However, it doesn't know anything about the safety measures themselves as we have not provided it with that information via the RAG pipeline. Let's try again but with RAG."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H4dZRAT2KRjk","outputId":"7422091d-2446-4177-8ef4-a63090d1360e"},"outputs":[{"name":"stdout","output_type":"stream","text":["The safety measures used in the development of Llama 2 include safety-specific data annotation and tuning, conducting red-teaming, and employing iterative evaluations. These measures were taken to increase the safety of the models and ensure responsible development. The paper also provides a thorough description of the fine-tuning methodology and approach to improving LLM safety. By sharing these details and being open about the process, the aim is to enable the community to reproduce fine-tuned LLMs and continue to improve their safety, promoting responsible development in the field.\n"]}],"source":["prompt = HumanMessage(\n","    content=augment_prompt(\n","        \"what safety measures were used in the development of llama 2?\"\n","    )\n",")\n","\n","res = chat(messages + [prompt])\n","print(res.content)"]},{"cell_type":"markdown","metadata":{"id":"JUeQ206AKRjl"},"source":["Now we get the right information, and if we add the prompt to the message history, our LLM will know how to provide us with an answer."]}],"metadata":{"kernelspec":{"display_name":"redacre","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"be77a53c5b504d0c9e61051945075d75":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_26a3c8ef0c924b5a994cc9c1c571a0bb","IPY_MODEL_e72b2017a11d4ccebf85aeb5d766797b","IPY_MODEL_d1fd6fc5669f4e06a0dea5a375978e3f"],"layout":"IPY_MODEL_d68bac75b3f64dd0ada66816957f685c"}},"26a3c8ef0c924b5a994cc9c1c571a0bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43572a2561ce46a09fbc6e2b3b6f1ee7","placeholder":"​","style":"IPY_MODEL_11707d43cd0c4eb688764d47bd996a89","value":"Downloading readme: 100%"}},"e72b2017a11d4ccebf85aeb5d766797b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_be20f87598d44bd69c4feb88aa06fba6","max":409,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f51a71e4773d4a00b7d988ec57843f10","value":409}},"d1fd6fc5669f4e06a0dea5a375978e3f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_452c59656294495eac2c4068ff46d9e0","placeholder":"​","style":"IPY_MODEL_9c10a94a32904eaa9d8994579403d225","value":" 409/409 [00:00&lt;00:00, 13.6kB/s]"}},"d68bac75b3f64dd0ada66816957f685c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43572a2561ce46a09fbc6e2b3b6f1ee7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11707d43cd0c4eb688764d47bd996a89":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be20f87598d44bd69c4feb88aa06fba6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f51a71e4773d4a00b7d988ec57843f10":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"452c59656294495eac2c4068ff46d9e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c10a94a32904eaa9d8994579403d225":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4c3b06b569f4d3ca03d1dc34ade186c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8bfd7cf50fb74a5e83de8481e7d5f096","IPY_MODEL_8b5b0caa99e343269349d099caa32400","IPY_MODEL_f2edb54556e6467bae3e593bf21d3587"],"layout":"IPY_MODEL_2d2e5eff50da4ad5969a96b65e4b8255"}},"8bfd7cf50fb74a5e83de8481e7d5f096":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f35565d6b57a4caabd190a359381dec8","placeholder":"​","style":"IPY_MODEL_5f03b7265e9949c5bafe28c0f3c82a8a","value":"Downloading data files: 100%"}},"8b5b0caa99e343269349d099caa32400":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_46d3f10caf044d31b37414caf155bcdf","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5eebbe28d48941398e16f58f5030cf25","value":1}},"f2edb54556e6467bae3e593bf21d3587":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a04928ba7fac4a5fa723b84048354849","placeholder":"​","style":"IPY_MODEL_4c521cfa98d441d790e5b3df709e79d3","value":" 1/1 [00:01&lt;00:00,  1.18s/it]"}},"2d2e5eff50da4ad5969a96b65e4b8255":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f35565d6b57a4caabd190a359381dec8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f03b7265e9949c5bafe28c0f3c82a8a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46d3f10caf044d31b37414caf155bcdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5eebbe28d48941398e16f58f5030cf25":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a04928ba7fac4a5fa723b84048354849":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c521cfa98d441d790e5b3df709e79d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"933016f0f472436da4dad83a422b3191":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_71dfa555bbbe4516a39f32e563adc544","IPY_MODEL_803e49c5d93845c3b0851e428e00718e","IPY_MODEL_53ac9402ac604404a875fbd409f4b254"],"layout":"IPY_MODEL_7e63974c92ee48daa5fc3fcd426747f6"}},"71dfa555bbbe4516a39f32e563adc544":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_baa24b7df0ce459bb55164d5dea6e824","placeholder":"​","style":"IPY_MODEL_d47e9e01ffca4b9a8c0a9ad8cf1df0cb","value":"Downloading data: 100%"}},"803e49c5d93845c3b0851e428e00718e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0df48c933c844e648b5c95b6be69b8a7","max":14417793,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dba0cdd2ceae4816a03a028b51597763","value":14417793}},"53ac9402ac604404a875fbd409f4b254":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0cebd9be5194a0f8c3ff4f24fc5a28d","placeholder":"​","style":"IPY_MODEL_a2b83a3410204bc18783f3d11683ece5","value":" 14.4M/14.4M [00:00&lt;00:00, 44.2MB/s]"}},"7e63974c92ee48daa5fc3fcd426747f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"baa24b7df0ce459bb55164d5dea6e824":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d47e9e01ffca4b9a8c0a9ad8cf1df0cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0df48c933c844e648b5c95b6be69b8a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dba0cdd2ceae4816a03a028b51597763":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0cebd9be5194a0f8c3ff4f24fc5a28d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2b83a3410204bc18783f3d11683ece5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86312d730fa042d9967c31e40d55ae14":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0b86daa5441a48e89140e83e99b930d7","IPY_MODEL_432c8285487541c494ec4ba8bfa45866","IPY_MODEL_61f66f846a434070bafb551653a90a48"],"layout":"IPY_MODEL_0daf46499af94c59ac39ef15d59157dc"}},"0b86daa5441a48e89140e83e99b930d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a76ac8ea4754380b7a1163d83a4f677","placeholder":"​","style":"IPY_MODEL_5eda70b126eb49a88130fe8a60f0677a","value":"Extracting data files: 100%"}},"432c8285487541c494ec4ba8bfa45866":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_95c6e9ec51534eeaa23824e511e09cd2","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc1628b74c3c4d57a058158f13aeed5c","value":1}},"61f66f846a434070bafb551653a90a48":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50d8a608cb5f43069eeac130c72c85dd","placeholder":"​","style":"IPY_MODEL_93f29f9c5daf4e30a378dd8d8006d817","value":" 1/1 [00:00&lt;00:00, 39.35it/s]"}},"0daf46499af94c59ac39ef15d59157dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a76ac8ea4754380b7a1163d83a4f677":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5eda70b126eb49a88130fe8a60f0677a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95c6e9ec51534eeaa23824e511e09cd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc1628b74c3c4d57a058158f13aeed5c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"50d8a608cb5f43069eeac130c72c85dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93f29f9c5daf4e30a378dd8d8006d817":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20fdabe2017446cab7d80adf31dc5edc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa15182dee014e0493770159c6fba390","IPY_MODEL_fd16cbe37d8847eda9417ec4eaa6d3eb","IPY_MODEL_afde652bddaa4a3e81eb3fb64e47b97e"],"layout":"IPY_MODEL_cc6bb80be5e842ef89ff6cdc8c1243b2"}},"fa15182dee014e0493770159c6fba390":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0101f9747c714c06a737370bc1616edf","placeholder":"​","style":"IPY_MODEL_a1c8a081bd454206b3005c34f6a26f38","value":"Generating train split: "}},"fd16cbe37d8847eda9417ec4eaa6d3eb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ca96c4da99945f1b96c7caf12d64d75","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a004fde8d6d74bf4b3b2128d9dd40f75","value":1}},"afde652bddaa4a3e81eb3fb64e47b97e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3a2b9f4795745e6bec8eb110c002e03","placeholder":"​","style":"IPY_MODEL_cedbc6b305cb402295f312bddcdb0c5a","value":" 4838/0 [00:00&lt;00:00, 10185.98 examples/s]"}},"cc6bb80be5e842ef89ff6cdc8c1243b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"0101f9747c714c06a737370bc1616edf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1c8a081bd454206b3005c34f6a26f38":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ca96c4da99945f1b96c7caf12d64d75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"a004fde8d6d74bf4b3b2128d9dd40f75":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a3a2b9f4795745e6bec8eb110c002e03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cedbc6b305cb402295f312bddcdb0c5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}